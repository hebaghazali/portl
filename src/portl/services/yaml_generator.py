"""
YAML generator service for creating migration configuration files.

This service converts wizard responses and configuration dictionaries
into properly formatted YAML migration job files.
"""

from typing import Dict, Any, List
import yaml
from datetime import datetime
from pathlib import Path
from rich.console import Console
from rich.panel import Panel
from rich.table import Table

from ..schema import SchemaValidator, generate_Job_template


class YamlGenerator:
    """Generates YAML configuration files from wizard responses."""
    
    def __init__(self):
        self.console = Console()
    
    def generate_yaml(self, config: Dict[str, Any]) -> str:
        """
        Generate a YAML configuration file from wizard responses.
        Auto-detects format (legacy vs Job) and generates appropriate YAML.
        
        Args:
            config: Configuration dictionary from wizard
            
        Returns:
            str: Formatted YAML content
        """
        # Detect format and generate appropriate YAML
        format_type = self._detect_config_format(config)
        
        if format_type == 'Job':
            return self.generate_Job_yaml(config)
        else:
            return self.generate_legacy_yaml(config)
    
    def generate_legacy_yaml(self, config: Dict[str, Any]) -> str:
        """
        Generate a legacy YAML configuration file from wizard responses.
        
        Args:
            config: Configuration dictionary from wizard
            
        Returns:
            str: Formatted YAML content
        """
        # Create the YAML structure
        yaml_config = self._build_yaml_structure(config)
        
        # Generate YAML with comments
        yaml_content = self._generate_yaml_with_comments(yaml_config)
        
        return yaml_content
    
    def _detect_config_format(self, config: Dict[str, Any]) -> str:
        """
        Detect whether config is for legacy format or Job.
        
        Args:
            config: Configuration dictionary
            
        Returns:
            str: 'legacy' or 'Job'
        """
        # Job format has 'steps' as a key indicator
        if 'steps' in config:
            return 'Job'
        
        # Legacy format has 'source' and 'destination'
        if 'source' in config and 'destination' in config:
            return 'legacy'
        
        # Default to legacy for backward compatibility
        return 'legacy'
    
    def generate_Job_yaml(self, config: Dict[str, Any]) -> str:
        """
        Generate a Job YAML configuration file with Steps DSL.
        
        Args:
            config: Configuration dictionary with Job structure
            
        Returns:
            str: Formatted Job YAML content
        """
        # Create the Job YAML structure
        yaml_config = self._build_Job_yaml_structure(config)
        
        # Generate YAML with comments
        yaml_content = self._generate_Job_yaml_with_comments(yaml_config)
        
        return yaml_content
    
    def _build_yaml_structure(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """Build the YAML structure from configuration."""
        yaml_config = {}
        
        # Add metadata
        yaml_config['# Generated by Portl Interactive Wizard'] = None
        yaml_config['# Created at'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        # Source configuration
        if 'source' in config:
            yaml_config['source'] = self._clean_config_section(config['source'])
        
        # Destination configuration
        if 'destination' in config:
            yaml_config['destination'] = self._clean_config_section(config['destination'])
        
        # Processing configuration
        if 'conflict' in config:
            yaml_config['conflict'] = config['conflict']
        
        if 'batch_size' in config:
            yaml_config['batch_size'] = config['batch_size']
        
        # Processing configuration (continued)
        if 'retry_strategy' in config:
            yaml_config['retry_strategy'] = config['retry_strategy']
        
        if 'max_retries' in config:
            yaml_config['max_retries'] = config['max_retries']
        
        if 'retry_delay' in config:
            yaml_config['retry_delay'] = config['retry_delay']
        
        # Schema and mapping configuration
        if 'mapping_strategy' in config:
            yaml_config['mapping_strategy'] = config['mapping_strategy']
        
        if 'schema_mapping' in config and config['schema_mapping']:
            yaml_config['schema_mapping'] = config['schema_mapping']
        
        if 'auto_create_columns' in config:
            yaml_config['auto_create_columns'] = config['auto_create_columns']
        
        if 'extra_columns_strategy' in config:
            yaml_config['extra_columns_strategy'] = config['extra_columns_strategy']
        
        # Merge options
        if 'merge_null_strategy' in config:
            yaml_config['merge_null_strategy'] = config['merge_null_strategy']
        
        if 'merge_add_timestamp' in config:
            yaml_config['merge_add_timestamp'] = config['merge_add_timestamp']
        
        if 'merge_timestamp_column' in config:
            yaml_config['merge_timestamp_column'] = config['merge_timestamp_column']
        
        # Validation options
        if 'dry_run_enabled' in config:
            yaml_config['dry_run_enabled'] = config['dry_run_enabled']
        
        if 'dry_run_preview_rows' in config:
            yaml_config['dry_run_preview_rows'] = config['dry_run_preview_rows']
        
        if 'validate_schema' in config:
            yaml_config['validate_schema'] = config['validate_schema']
        
        if 'schema_validation_level' in config:
            yaml_config['schema_validation_level'] = config['schema_validation_level']
        
        if 'validate_row_count' in config:
            yaml_config['validate_row_count'] = config['validate_row_count']
        
        if 'row_count_tolerance' in config:
            yaml_config['row_count_tolerance'] = config['row_count_tolerance']
        
        if 'validate_data_sampling' in config:
            yaml_config['validate_data_sampling'] = config['validate_data_sampling']
        
        if 'data_sample_size' in config:
            yaml_config['data_sample_size'] = config['data_sample_size']
        
        if 'validation_checks' in config and config['validation_checks']:
            yaml_config['validation_checks'] = config['validation_checks']
        
        if 'monitor_performance' in config:
            yaml_config['monitor_performance'] = config['monitor_performance']
        
        if 'max_job_duration' in config:
            yaml_config['max_job_duration'] = config['max_job_duration']
        
        if 'min_throughput' in config:
            yaml_config['min_throughput'] = config['min_throughput']
        
        # Advanced configurations
        if 'transformations' in config and config['transformations']:
            yaml_config['transformations'] = config['transformations']
        
        if 'hooks' in config and config['hooks']:
            yaml_config['hooks'] = config['hooks']
        
        # Add default parallel jobs if not specified
        if 'parallel_jobs' not in yaml_config:
            yaml_config['parallel_jobs'] = 1
        
        return yaml_config
    
    def _clean_config_section(self, section: Dict[str, Any]) -> Dict[str, Any]:
        """Clean and organize a configuration section."""
        cleaned = {}
        
        # Always put type first
        if 'type' in section:
            cleaned['type'] = section['type']
        
        # Add other keys in logical order
        key_order = [
            'host', 'port', 'database', 'username', 'password', 'schema', 'table', 'query',
            'path', 'spreadsheet_id', 'sheet_name', 'credentials_path'
        ]
        
        for key in key_order:
            if key in section:
                cleaned[key] = section[key]
        
        # Add any remaining keys
        for key, value in section.items():
            if key not in cleaned:
                cleaned[key] = value
        
        return cleaned
    
    def _generate_yaml_with_comments(self, config: Dict[str, Any]) -> str:
        """Generate YAML with helpful comments."""
        lines = []
        
        # Header comment
        lines.append("# Portl Migration Job Configuration")
        lines.append("# Generated by Interactive Wizard")
        lines.append(f"# Created: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        lines.append("")
        
        # Source section
        if 'source' in config:
            lines.append("# Source: Where to read data FROM")
            lines.extend(self._yaml_section_to_lines('source', config['source']))
            lines.append("")
        
        # Destination section
        if 'destination' in config:
            lines.append("# Destination: Where to write data TO")
            lines.extend(self._yaml_section_to_lines('destination', config['destination']))
            lines.append("")
        
        # Processing configuration
        lines.append("# Processing Configuration")
        
        if 'conflict' in config:
            lines.append("# Primary key conflict resolution strategy")
            lines.append("# Options: skip, overwrite, merge, fail")
            lines.append(f"conflict: {config['conflict']}")
            lines.append("")
        
        if 'batch_size' in config:
            lines.append("# Number of rows to process in each batch")
            lines.append(f"batch_size: {config['batch_size']}")
            lines.append("")
        
        if 'parallel_jobs' in config:
            lines.append("# Number of parallel processing jobs")
            lines.append(f"parallel_jobs: {config['parallel_jobs']}")
            lines.append("")
        
        if 'retry_strategy' in config:
            lines.append("# Retry strategy on failure")
            lines.append("# Options: skip, retry_n_times, fail_fast")
            lines.append(f"retry_strategy: {config['retry_strategy']}")
            lines.append("")
        
        if 'max_retries' in config:
            lines.append("# Maximum retry attempts")
            lines.append(f"max_retries: {config['max_retries']}")
            lines.append("")
        
        if 'retry_delay' in config:
            lines.append("# Delay between retries (seconds)")
            lines.append(f"retry_delay: {config['retry_delay']}")
            lines.append("")
        
        # Schema and mapping configuration
        if 'mapping_strategy' in config:
            lines.append("# Schema Mapping Strategy")
            lines.append("# Options: auto_map_by_name, manual_mapping, no_mapping")
            lines.append(f"mapping_strategy: {config['mapping_strategy']}")
            lines.append("")
        
        if 'schema_mapping' in config:
            lines.append("# Column Mapping: source_column -> destination_column")
            lines.extend(self._yaml_section_to_lines('schema_mapping', config['schema_mapping']))
            lines.append("")
        
        if 'auto_create_columns' in config:
            lines.append("# Auto-create missing columns in destination")
            lines.append(f"auto_create_columns: {str(config['auto_create_columns']).lower()}")
            lines.append("")
        
        if 'extra_columns_strategy' in config:
            lines.append("# How to handle extra destination columns")
            lines.append("# Options: ignore, error, warn")
            lines.append(f"extra_columns_strategy: {config['extra_columns_strategy']}")
            lines.append("")
        
        # Merge configuration
        if 'merge_null_strategy' in config:
            lines.append("# Merge Strategy for Null Values")
            lines.append("# Options: keep_existing, overwrite_with_null, skip_null")
            lines.append(f"merge_null_strategy: {config['merge_null_strategy']}")
            lines.append("")
        
        if 'merge_add_timestamp' in config:
            lines.append("# Add timestamp tracking for merged records")
            lines.append(f"merge_add_timestamp: {str(config['merge_add_timestamp']).lower()}")
            lines.append("")
        
        if 'merge_timestamp_column' in config:
            lines.append("# Timestamp column name for merge tracking")
            lines.append(f"merge_timestamp_column: {config['merge_timestamp_column']}")
            lines.append("")
        
        # Validation configuration
        if any(key.startswith('dry_run') or key.startswith('validate') or key.startswith('monitor') for key in config.keys()):
            lines.append("# Validation and Testing Configuration")
            
            if 'dry_run_enabled' in config:
                lines.append("# Enable dry run preview (test without writing data)")
                lines.append(f"dry_run_enabled: {str(config['dry_run_enabled']).lower()}")
                lines.append("")
            
            if 'dry_run_preview_rows' in config:
                lines.append("# Number of rows to preview in dry run")
                lines.append(f"dry_run_preview_rows: {config['dry_run_preview_rows']}")
                lines.append("")
            
            if 'validate_schema' in config:
                lines.append("# Enable schema compatibility validation")
                lines.append(f"validate_schema: {str(config['validate_schema']).lower()}")
                lines.append("")
            
            if 'schema_validation_level' in config:
                lines.append("# Schema validation level: strict, warn, ignore")
                lines.append(f"schema_validation_level: {config['schema_validation_level']}")
                lines.append("")
            
            if 'validate_row_count' in config:
                lines.append("# Enable row count comparison after migration")
                lines.append(f"validate_row_count: {str(config['validate_row_count']).lower()}")
                lines.append("")
            
            if 'row_count_tolerance' in config:
                lines.append("# Row count difference tolerance (%)")
                lines.append(f"row_count_tolerance: {config['row_count_tolerance']}")
                lines.append("")
            
            if 'validate_data_sampling' in config:
                lines.append("# Enable data sampling validation")
                lines.append(f"validate_data_sampling: {str(config['validate_data_sampling']).lower()}")
                lines.append("")
            
            if 'data_sample_size' in config:
                lines.append("# Sample size for data validation")
                lines.append(f"data_sample_size: {config['data_sample_size']}")
                lines.append("")
            
            if 'validation_checks' in config:
                lines.append("# Data validation checks to perform")
                lines.extend(self._yaml_section_to_lines('validation_checks', config['validation_checks']))
                lines.append("")
            
            if 'monitor_performance' in config:
                lines.append("# Enable performance monitoring")
                lines.append(f"monitor_performance: {str(config['monitor_performance']).lower()}")
                lines.append("")
            
            if 'max_job_duration' in config:
                lines.append("# Maximum job duration (minutes) before alert")
                lines.append(f"max_job_duration: {config['max_job_duration']}")
                lines.append("")
            
            if 'min_throughput' in config:
                lines.append("# Minimum throughput (rows/second) before alert")
                lines.append(f"min_throughput: {config['min_throughput']}")
                lines.append("")
        
        # Advanced configurations
        if 'transformations' in config:
            lines.append("# Data Transformations")
            lines.extend(self._yaml_section_to_lines('transformations', config['transformations']))
            lines.append("")
        
        if 'hooks' in config:
            lines.append("# Processing Hooks: Scripts to run at different stages")
            lines.extend(self._yaml_section_to_lines('hooks', config['hooks']))
            lines.append("")
        
        return '\n'.join(lines)
    
    def _build_Job_yaml_structure(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """Build the Job YAML structure from configuration."""
        yaml_config = {}
        
        # Connections section
        if 'connections' in config and config['connections']:
            yaml_config['connections'] = config['connections']
        
        # Transaction configuration
        if 'transaction' in config:
            yaml_config['transaction'] = config['transaction']
        
        # Steps section (required)
        if 'steps' in config:
            yaml_config['steps'] = config['steps']
        
        return yaml_config
    
    def _generate_Job_yaml_with_comments(self, config: Dict[str, Any]) -> str:
        """Generate Job YAML with helpful comments."""
        lines = []
        
        # Header comment
        lines.append("# Portl Job Configuration - Steps DSL")
        lines.append("# Multi-step workflow with transactions, context passing, and retries")
        lines.append(f"# Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        lines.append("")
        
        # Connections section
        if 'connections' in config:
            lines.append("# Connection definitions (shared across steps)")
            lines.extend(self._yaml_section_to_lines('connections', config['connections']))
            lines.append("")
        
        # Transaction section
        if 'transaction' in config:
            lines.append("# Transaction management (DB scope only)")
            lines.extend(self._yaml_section_to_lines('transaction', config['transaction']))
            lines.append("")
        
        # Steps section
        if 'steps' in config:
            lines.append("# Processing steps (executed in order)")
            lines.extend(self._yaml_section_to_lines('steps', config['steps']))
            lines.append("")
        
        return '\n'.join(lines)
    
    def _yaml_section_to_lines(self, section_name: str, section_data: Any) -> List[str]:
        """Convert a section to YAML lines."""
        # Use PyYAML to generate the section
        section_yaml = yaml.dump({section_name: section_data}, default_flow_style=False, sort_keys=False)
        
        # Split into lines and return (excluding the first line which is just the section name)
        lines = section_yaml.strip().split('\n')
        return lines
    
    def validate_generated_yaml(self, yaml_content: str) -> Dict[str, Any]:
        """
        Validate the generated YAML content using the schema validator.
        
        Args:
            yaml_content: YAML content to validate
            
        Returns:
            Dict with validation results
        """
        try:
            # Parse YAML to check syntax
            parsed = yaml.safe_load(yaml_content)
            
            if not parsed:
                return {
                    "valid": False,
                    "errors": ["YAML content is empty"],
                    "warnings": []
                }
            
            # Use the schema validator for comprehensive validation
            # Auto-detect format and validate accordingly
            format_type = SchemaValidator.detect_job_format(parsed)
            
            if format_type == 'Job':
                job_config = SchemaValidator.validate_Job_config(parsed)
            else:
                job_config = SchemaValidator.validate_yaml_config(parsed)
            
            # If we get here, validation passed
            validation_result = {
                "valid": True,
                "errors": [],
                "warnings": []
            }
            
            # Add warnings for missing optional but recommended fields
            if 'conflict' not in parsed:
                validation_result["warnings"].append("No conflict resolution strategy specified, using default 'overwrite'")
            
            if 'batch_size' not in parsed:
                validation_result["warnings"].append("No batch size specified, using default 1000")
            
            if 'parallel_jobs' not in parsed:
                validation_result["warnings"].append("No parallel jobs specified, using default 1")
            
            return validation_result
            
        except yaml.YAMLError as e:
            return {
                "valid": False,
                "errors": [f"YAML syntax error: {e}"],
                "warnings": []
            }
        except ValueError as e:
            return {
                "valid": False,
                "errors": [str(e)],
                "warnings": []
            }
        except Exception as e:
            return {
                "valid": False,
                "errors": [f"Validation error: {e}"],
                "warnings": []
            }
    
    def generate_job_plan_preview(self, config: Dict[str, Any]) -> str:
        """
        Generate a human-readable job plan preview (auto-detects format).
        
        Args:
            config: Configuration dictionary
            
        Returns:
            str: Formatted job plan description
        """
        format_type = self._detect_config_format(config)
        
        if format_type == 'Job':
            return self.generate_job_plan_preview_v2(config)
        else:
            return self.generate_job_plan_preview_legacy(config)
    
    def generate_job_plan_preview_v2(self, config: Dict[str, Any]) -> str:
        """
        Generate a human-readable job plan preview for Job.
        
        Args:
            config: Job configuration dictionary
            
        Returns:
            str: Formatted job plan description
        """
        lines = []
        lines.append("Job Workflow Plan")
        lines.append("=" * 50)
        
        # Connections information
        if 'connections' in config and config['connections']:
            lines.append(f"\nConnections:")
            for conn_name, conn_config in config['connections'].items():
                conn_type = conn_config.get('type', 'Unknown')
                lines.append(f"   {conn_name}: {conn_type.upper()}")
        
        # Transaction information
        if 'transaction' in config:
            transaction_scope = config['transaction'].get('scope', 'db')
            lines.append(f"\nTransaction Scope: {transaction_scope.upper()}")
        
        # Steps information
        if 'steps' in config and config['steps']:
            lines.append(f"\nProcessing Steps ({len(config['steps'])} steps):")
            for i, step in enumerate(config['steps'], 1):
                step_id = step.get('id', f'step_{i}')
                step_type = step.get('type', 'unknown')
                connection = step.get('connection', 'none')
                lines.append(f"   {i}. {step_id} ({step_type})")
                if connection != 'none':
                    lines.append(f"      Connection: {connection}")
                if step.get('save_as'):
                    lines.append(f"      Saves as: {step['save_as']}")
                if step.get('when'):
                    lines.append(f"      Condition: {step['when']}")
                if step.get('batch'):
                    lines.append(f"      Batched: {step['batch'].get('from', 'N/A')}")
        
        return '\n'.join(lines)
    
    def generate_job_plan_preview_legacy(self, config: Dict[str, Any]) -> str:
        """
        Generate a human-readable job plan preview for legacy format.
        
        Args:
            config: Configuration dictionary
            
        Returns:
            str: Formatted job plan description
        """
        lines = []
        lines.append("Migration Job Plan")
        lines.append("=" * 50)
        
        # Source information
        if 'source' in config:
            source = config['source']
            lines.append(f"\nSource: {source.get('type', 'Unknown').upper()}")
            if source.get('type') == 'csv':
                lines.append(f"   File: {source.get('path', 'N/A')}")
            elif source.get('type') in ['postgres', 'mysql']:
                lines.append(f"   Host: {source.get('host', 'N/A')}")
                lines.append(f"   Database: {source.get('database', 'N/A')}")
                lines.append(f"   Table/Query: {source.get('table') or source.get('query', 'N/A')}")
            elif source.get('type') == 'google_sheets':
                lines.append(f"   Spreadsheet ID: {source.get('spreadsheet_id', 'N/A')}")
                lines.append(f"   Sheet: {source.get('sheet_name', 'N/A')}")
        
        # Destination information
        if 'destination' in config:
            dest = config['destination']
            lines.append(f"\nDestination: {dest.get('type', 'Unknown').upper()}")
            if dest.get('type') == 'csv':
                lines.append(f"   File: {dest.get('path', 'N/A')}")
            elif dest.get('type') in ['postgres', 'mysql']:
                lines.append(f"   Host: {dest.get('host', 'N/A')}")
                lines.append(f"   Database: {dest.get('database', 'N/A')}")
                lines.append(f"   Table: {dest.get('table', 'N/A')}")
            elif dest.get('type') == 'google_sheets':
                lines.append(f"   Spreadsheet ID: {dest.get('spreadsheet_id', 'N/A')}")
                lines.append(f"   Sheet: {dest.get('sheet_name', 'N/A')}")
        
        # Processing configuration
        lines.append(f"\nProcessing Configuration:")
        lines.append(f"   Conflict Strategy: {config.get('conflict', 'overwrite')}")
        lines.append(f"   Batch Size: {config.get('batch_size', 1000)} rows")
        lines.append(f"   Parallel Jobs: {config.get('parallel_jobs', 1)}")
        
        # Optional configurations
        if config.get('schema_mapping'):
            lines.append(f"\nColumn Mapping:")
            for source_col, dest_col in config['schema_mapping'].items():
                lines.append(f"   {source_col} -> {dest_col}")
        
        if config.get('transformations'):
            lines.append(f"\nData Transformations:")
            for transform in config['transformations']:
                lines.append(f"   {transform.get('column', 'N/A')}: {transform.get('operation', 'N/A')}")
        
        if config.get('hooks'):
            lines.append(f"\nProcessing Hooks:")
            hooks = config['hooks']
            for hook_type, hook_value in hooks.items():
                if hook_value:
                    lines.append(f"   {hook_type}: {hook_value}")
        
        return '\n'.join(lines)
    
    def display_job_plan_preview(self, config: Dict[str, Any]) -> None:
        """
        Display a formatted job plan preview.
        
        Args:
            config: Configuration dictionary
        """
        plan = self.generate_job_plan_preview(config)
        panel = Panel(plan, title="[bold green]Job Plan Preview[/bold green]", border_style="green")
        self.console.print(panel)
    
    def save_yaml_with_mode_handling(self, 
                                   yaml_content: str, 
                                   output_path: Path, 
                                   overwrite: bool = False) -> bool:
        """
        Save YAML content with proper mode handling (overwrite vs append).
        
        Args:
            yaml_content: YAML content to save
            output_path: Path where to save the file
            overwrite: Whether to overwrite existing file without asking
            
        Returns:
            bool: True if file was saved successfully
        """
        if output_path.exists() and not overwrite:
            # File exists, ask user what to do
            self.console.print(f"\n[yellow]File already exists: {output_path}[/yellow]")
            
            table = Table(show_header=False, box=None)
            table.add_row("[1]", "Overwrite existing file")
            table.add_row("[2]", "Create backup and overwrite")
            table.add_row("[3]", "Choose different filename")
            table.add_row("[4]", "Cancel")
            
            self.console.print(table)
            
            while True:
                choice = self.console.input("\nChoose an option [1-4]: ").strip()
                
                if choice == "1":
                    # Overwrite
                    break
                elif choice == "2":
                    # Create backup
                    backup_path = output_path.with_suffix(f"{output_path.suffix}.backup")
                    output_path.rename(backup_path)
                    self.console.print(f"[green]Backup created: {backup_path}[/green]")
                    break
                elif choice == "3":
                    # Choose different filename
                    new_name = self.console.input("Enter new filename: ").strip()
                    if new_name:
                        output_path = output_path.parent / new_name
                        if not output_path.suffix:
                            output_path = output_path.with_suffix('.yaml')
                    break
                elif choice == "4":
                    # Cancel
                    self.console.print("[yellow]Save cancelled.[/yellow]")
                    return False
                else:
                    self.console.print("[red]Invalid choice. Please enter 1-4.[/red]")
        
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(yaml_content)
            
            self.console.print(f"[green]✅ YAML configuration saved: {output_path}[/green]")
            return True
            
        except Exception as e:
            self.console.print(f"[red]❌ Failed to save file: {e}[/red]")
            return False
    
    def generate_and_preview_yaml(self, config: Dict[str, Any], show_preview: bool = True) -> str:
        """
        Generate YAML and optionally show preview with syntax highlighting.
        
        Args:
            config: Configuration dictionary
            show_preview: Whether to display the preview
            
        Returns:
            str: Generated YAML content
        """
        # Generate YAML content
        yaml_content = self.generate_yaml(config)
        
        if show_preview:
            # Show job plan preview
            self.display_job_plan_preview(config)
            self.console.print()  # Add spacing
        
        return yaml_content
    
    def generate_Job_template(self) -> str:
        """
        Generate a Job template with Steps DSL examples.
        
        Returns:
            str: Job template YAML content
        """
        return generate_Job_template()
    
    def display_validation_results(self, validation_result: Dict[str, Any]) -> None:
        """
        Display YAML validation results with formatted error reporting.
        
        Args:
            validation_result: Result from validate_generated_yaml()
        """
        if validation_result['valid']:
            self.console.print("[green]YAML validation passed![/green]")
            
            if validation_result.get('warnings'):
                self.console.print("\n[yellow]Warnings:[/yellow]")
                for warning in validation_result['warnings']:
                    self.console.print(f"  - {warning}")
        else:
            self.console.print("[red]YAML validation failed![/red]")
            
            if validation_result.get('errors'):
                self.console.print("\n[red]Errors:[/red]")
                for error in validation_result['errors']:
                    self.console.print(f"  - {error}")
            
            if validation_result.get('warnings'):
                self.console.print("\n[yellow]Warnings:[/yellow]")
                for warning in validation_result['warnings']:
                    self.console.print(f"  - {warning}")
    
    def validate_and_report_yaml(self, yaml_content: str) -> bool:
        """
        Validate YAML content and display formatted results.
        
        Args:
            yaml_content: YAML content to validate
            
        Returns:
            bool: True if validation passed
        """
        validation_result = self.validate_generated_yaml(yaml_content)
        self.display_validation_results(validation_result)
        return validation_result['valid']
